{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O6n-60U9sme-"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7D1cY5QLdZDm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHMYngOfcPXS"
      },
      "source": [
        "#Download\n",
        "\n",
        "- If you want run this code, you need to create the Kaggle API key. The next step was extracted  [here](https://www.kaggle.com/discussions/general/74235)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "C1V3E733QMTp",
        "outputId": "b1127cc7-a298-4883-9187-e49e76a058b3"
      },
      "outputs": [],
      "source": [
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oL5J8ilr5EO",
        "outputId": "9f42f382-4654-491f-b4ce-850412ab9fc8"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json  ~/.kaggle/\n",
        "!chmod 600 kaggle.json\n",
        "!kaggle datasets download -d arpitjain007/dog-vs-cat-fastai\n",
        "!unzip dog-vs-cat-fastai.zip\n",
        "!mv dogscats/valid dogscats/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6blwQIqcHpG"
      },
      "source": [
        "#Load and proccess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z5IMdQXUQUMa"
      },
      "outputs": [],
      "source": [
        "#test\n",
        "dog_test_path = \"dogscats/test/dogs\"\n",
        "cat_test_path = \"dogscats/test/cats\"\n",
        "\n",
        "dog_test = os.listdir(dog_test_path)\n",
        "cat_test = os.listdir(cat_test_path)\n",
        "\n",
        "dog_test_paths = [os.path.join(dog_test_path, filename) for filename in dog_test]\n",
        "cat_test_paths = [os.path.join(cat_test_path, filename) for filename in cat_test]\n",
        "\n",
        "test_data = dog_test_paths + cat_test_paths\n",
        "random.shuffle(test_data)\n",
        "\n",
        "#train y val\n",
        "dog_train_path = \"dogscats/train/dogs\"\n",
        "cat_train_path = \"dogscats/train/cats\"\n",
        "\n",
        "dog_train = os.listdir(dog_train_path)\n",
        "cat_train = os.listdir(cat_train_path)\n",
        "\n",
        "dog_train_paths = [os.path.join(dog_train_path, filename) for filename in dog_train]\n",
        "cat_train_paths = [os.path.join(cat_train_path, filename) for filename in cat_train]\n",
        "\n",
        "split_ratio = 0.8\n",
        "num_dog_train = int(len(dog_train_paths) * split_ratio)\n",
        "num_cat_train = int(len(cat_train_paths) * split_ratio)\n",
        "\n",
        "dog_train_data = dog_train_paths[:num_dog_train]\n",
        "cat_train_data = cat_train_paths[:num_cat_train]\n",
        "\n",
        "dog_val_data = dog_train_paths[num_dog_train:]\n",
        "cat_val_data = cat_train_paths[num_cat_train:]\n",
        "\n",
        "train_data = dog_train_data + cat_train_data\n",
        "val_data = dog_val_data + cat_val_data\n",
        "\n",
        "random.shuffle(train_data)\n",
        "random.shuffle(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xpivNsosl5k2"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bP-h6qdaMaDM"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset class for loading images from file paths and applying transformations.\n",
        "\n",
        "    Args:\n",
        "        file_paths (list): List of file paths for the images.\n",
        "        transform (callable, optional): A function/transform that takes in an image and returns a\n",
        "            transformed version. Default is None.\n",
        "\n",
        "    Methods:\n",
        "        __init__(self, file_paths, transform=None):\n",
        "            Initializes a new instance of the CustomDataset class.\n",
        "\n",
        "        __len__(self):\n",
        "            Returns the total number of samples in the dataset.\n",
        "\n",
        "        __getitem__(self, idx):\n",
        "            Retrieves the sample at the specified index.\n",
        "\n",
        "    Attributes:\n",
        "        file_paths (list): List of file paths for the images.\n",
        "        transform (callable): A function/transform applied to the image.\n",
        "\n",
        "    Example:\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((64, 64)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "        # Example usage:\n",
        "        dataset = CustomDataset(file_paths=train_data, transform=transform)\n",
        "    \"\"\"\n",
        "    def __init__(self, file_paths, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = 1 if 'dog.' in img_path else 0\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = CustomDataset(train_data, transform=transform)\n",
        "val_dataset = CustomDataset(val_data, transform=transform)\n",
        "test_dataset = CustomDataset(test_data, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfVcyQsBcLo7"
      },
      "source": [
        "# Build Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9t2h_NhUJbeu"
      },
      "outputs": [],
      "source": [
        "class EvolvedCNN(nn.Module):\n",
        "    \"\"\"\n",
        "      EvolvedCNN is a convolutional neural network with an evolved architecture.\n",
        "\n",
        "      Args:\n",
        "          hyperparameters (list): List of hyperparameters representing the number of neurons\n",
        "                                  in each convolutional layer.\n",
        "          image_size (tuple): Tuple representing the input image size (height, width).\n",
        "\n",
        "      Attributes:\n",
        "          conv_layer_1 (nn.Sequential): First convolutional block.\n",
        "          conv_layer_2 (nn.Sequential): Second convolutional block.\n",
        "          conv_layer_3 (nn.Sequential): Third convolutional block.\n",
        "          conv_layer_4 (nn.Sequential): Fourth convolutional block.\n",
        "          image_size (tuple): Input image size.\n",
        "          classifier (nn.Sequential): Classifier block with a linear layer.\n",
        "\n",
        "      Methods:\n",
        "          build_conv_block(in_channels, out_channels): Helper method to build a convolutional block.\n",
        "\n",
        "      Forward:\n",
        "        Perform forward pass through the convolutional blocks and classifier.\n",
        "    \"\"\"\n",
        "    def __init__(self, hyperparameters, image_size):\n",
        "        super(EvolvedCNN, self).__init__()\n",
        "        self.conv_layer_1 = self.build_conv_block(3, hyperparameters[0])\n",
        "        self.conv_layer_2 = self.build_conv_block(hyperparameters[0], hyperparameters[1])\n",
        "        self.conv_layer_3 = self.build_conv_block(hyperparameters[1], hyperparameters[2])\n",
        "        self.conv_layer_4 = self.build_conv_block(hyperparameters[2], hyperparameters[3])\n",
        "\n",
        "        self.image_size = image_size\n",
        "        in_features = hyperparameters[3] * 2 * 2\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, out_features=2))\n",
        "\n",
        "    def build_conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer_1(x)\n",
        "        x = self.conv_layer_2(x)\n",
        "        x = self.conv_layer_3(x)\n",
        "        x = self.conv_layer_4(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0djrVz35dnwk"
      },
      "source": [
        "#Train phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PdPfKv4klWBL"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, model, criterion, optimizer):\n",
        "    \"\"\"\n",
        "    Train the model on a training dataset.\n",
        "\n",
        "    Args:\n",
        "        train_loader (DataLoader): DataLoader for the training dataset.\n",
        "        model (nn.Module): Model to train.\n",
        "        criterion (nn.Module): Loss function.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer.\n",
        "        epoch (int): Number of epochs.\n",
        "\n",
        "    Returns:\n",
        "        float: Average loss on the training dataset.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f'Train step', leave=False):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    return average_loss\n",
        "\n",
        "def validation(test_loader, model, criterion):\n",
        "    \"\"\"\n",
        "    Evaluate the model on a test dataset.\n",
        "\n",
        "    Args:\n",
        "        test_loader (DataLoader): DataLoader for the test dataset.\n",
        "        model (nn.Module): Model to evaluate.\n",
        "        criterion (nn.Module): Loss function.\n",
        "\n",
        "    Returns:\n",
        "        float: Average loss on the test dataset.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluation step\", leave=False):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(test_loader)\n",
        "    return average_loss\n",
        "\n",
        "\n",
        "def evaluation(test_loader, model, criterion):\n",
        "    \"\"\"\n",
        "    Evaluate the model on a test dataset.\n",
        "\n",
        "    Args:\n",
        "        test_loader (DataLoader): DataLoader for the test dataset.\n",
        "        model (nn.Module): Model to evaluate.\n",
        "        criterion (nn.Module): Loss function.\n",
        "\n",
        "    Returns:\n",
        "        float: Average F1-score on the test dataset.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluation step\", leave=False):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    average_loss = total_loss / len(test_loader)\n",
        "    return average_loss, f1\n",
        "\n",
        "def train_step(train_loader, val_loader, model, criterion, optimizer, epochs):\n",
        "  \"\"\"\n",
        "    Train and validate a model over multiple epochs.\n",
        "\n",
        "    Args:\n",
        "        train_loader (DataLoader): DataLoader for the training dataset.\n",
        "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
        "        model (nn.Module): Model to train and validate.\n",
        "        criterion (nn.Module): Loss function.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer.\n",
        "        epochs (int): Number of epochs.\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: Trained model.\n",
        "  \"\"\"\n",
        "  #loss_thr=10000\n",
        "  for epoch in range(epochs):\n",
        "      average_loss_train = train(train_loader, model, criterion, optimizer)\n",
        "      print(f\"average_loss_train de la época: {epoch} -- train_loss: {average_loss_train}\")\n",
        "      average_loss_val = validation(val_loader, model, criterion)\n",
        "      print(f\"average_loss_val de la época: {epoch} -- val_loss: {average_loss_val}\")\n",
        "      #if average_loss_val < loss_thr:\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-w5tJphduiO"
      },
      "source": [
        "#Genetic algorithm\n",
        "\n",
        "- Our chromosome is a list of candidate neurons to build a convolutional neural network. \\[32, 64,128, 256, 512] (Surround 120 possible architectures)\n",
        "\n",
        "- Fitness is the f1_score in the test step, after training our network in 5 epochs.\n",
        "\n",
        "- Two points were used for the crossing, the parent selectors were Tournament without replacement and finally the mutation, exchange (same as N-Queens)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CskwtVzCw9Qo"
      },
      "outputs": [],
      "source": [
        "def init_pop(num_elements, neurons_candidates = [32, 64,128, 256, 512]):\n",
        "  \"\"\"\n",
        "    Initialize a population of neural network architectures with random hyperparameters.\n",
        "\n",
        "    Args:\n",
        "        num_elements (int): Number of architectures to generate.\n",
        "        neurons_candidates (list): List of possible values for the number of neurons.\n",
        "\n",
        "    Returns:\n",
        "        list: List of hyperparameter combinations representing neural network architectures.\n",
        "  \"\"\"\n",
        "  i = 0\n",
        "  hyperparameters_custom = []\n",
        "\n",
        "  while i < num_elements:\n",
        "    candidates = random.choices(neurons_candidates, k=4)\n",
        "    if candidates not in hyperparameters_custom:\n",
        "      hyperparameters_custom.append(candidates)\n",
        "      i+=1\n",
        "  return hyperparameters_custom\n",
        "\n",
        "class Chromosome():\n",
        "    \"\"\"\n",
        "        Initializes a Chromosome object.\n",
        "\n",
        "        Args:\n",
        "            chromosome (list): The genetic representation of the chromosome.\n",
        "            fitness (float): The fitness score of the chromosome.\n",
        "    \"\"\"\n",
        "    def __init__(self, chromosome, fitness):\n",
        "        self.chromosome = chromosome\n",
        "        self.fitness = fitness\n",
        "\n",
        "\n",
        "def fitness(chromosome, train_loader, val_loader, test_loader, model, criterion, epochs=10, learning_rate=1e-4, image_size = (64, 64)):\n",
        "    \"\"\"\n",
        "      Evaluate the performance of a chromosome in terms of F1-score on a test dataset.\n",
        "\n",
        "      Args:\n",
        "        chromosome (list): List of model hyperparameters.\n",
        "        train_loader (DataLoader): DataLoader for the training dataset.\n",
        "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
        "        test_loader (DataLoader): DataLoader for the test dataset.\n",
        "        model (nn.Module): Evolved architecture model.\n",
        "        criterion (nn.Module): Loss function.\n",
        "        epochs (int): Number of epochs for training.\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "        image_size (tuple): Size of the input image.\n",
        "\n",
        "      Returns:\n",
        "        float: Average F1-score on the test dataset.\n",
        "    \"\"\"\n",
        "    evolved_cnn = model(chromosome, image_size).to(device)\n",
        "    optimizer = optim.Adam(evolved_cnn.parameters(), lr=learning_rate)\n",
        "    evolved_cnn = train_step(train_loader, val_loader, evolved_cnn, criterion, optimizer, epochs)\n",
        "    average_loss_test, f1_score_test = evaluation(test_loader, evolved_cnn, criterion)\n",
        "    print(f\"Test -> average_loss_test: {average_loss_test} -- Metric: f1 score: {f1_score_test}\")\n",
        "    return f1_score_test\n",
        "\n",
        "def crossover_two_points(parent1, parent2, crossover_rate=0.7):\n",
        "    \"\"\"\n",
        "    Perform two-point crossover between two chromosomes.\n",
        "\n",
        "    Args:\n",
        "        parent1 (list): First chromosome.\n",
        "        parent2 (list): Second chromosome.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Two descendants generated through two-point crossover.\n",
        "    \"\"\"\n",
        "    if random.random() < crossover_rate:\n",
        "        return parent1, parent2\n",
        "\n",
        "    point1 = random.randint(0, len(parent1) - 1)\n",
        "    point2 = random.randint(point1, len(parent1))\n",
        "\n",
        "    child1 = parent1[:point1] + parent2[point1:point2] + parent1[point2:]\n",
        "    child2 = parent2[:point1] + parent1[point1:point2] + parent2[point2:]\n",
        "\n",
        "    return child1, child2\n",
        "\n",
        "\n",
        "def mutation(chromosome, mutation_rate=0.5):\n",
        "    \"\"\"\n",
        "    Apply mutation on a chromosome by performing a swap between two genes.\n",
        "\n",
        "    Args:\n",
        "        chromosome (list): Chromosome to mutate, represented as a list.\n",
        "        mutation_rate (float): Mutation rate controlling the probability of applying the mutation.\n",
        "                              It should be in the range [0, 1]. Default is 0.5.\n",
        "\n",
        "    Returns:\n",
        "        list: Mutated chromosome.\n",
        "    \"\"\"\n",
        "    mutated_chromosome = chromosome.copy()\n",
        "\n",
        "    if random.random() <= mutation_rate:\n",
        "        index1, index2 = random.sample(range(len(chromosome)), 2)\n",
        "\n",
        "        mutated_chromosome[index1], mutated_chromosome[index2] = mutated_chromosome[index2], mutated_chromosome[index1]\n",
        "\n",
        "    return mutated_chromosome\n",
        "\n",
        "def build_chromosome(pop, train_loader, val_loader, test_loader, model, criterion,\\\n",
        "                     epochs=10, learning_rate=1e-4, image_size=(64, 64)):\n",
        "  chromosome = []\n",
        "  print(\"build chromosomes step....\")\n",
        "  for config in pop:\n",
        "        fitness_value = fitness(config, train_loader, val_loader, test_loader, model, criterion,\\\n",
        "                            epochs=epochs, learning_rate=learning_rate, image_size=image_size)\n",
        "        chromosome.append(Chromosome(config, fitness_value))\n",
        "  return chromosome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ySRGA1VvFudR"
      },
      "outputs": [],
      "source": [
        "class Selection(ABC):\n",
        "    \"\"\"\n",
        "    Clase abstracta para representar una selección en un algoritmo genético.\n",
        "\n",
        "    Args:\n",
        "        chromosomes (list): Lista de cromosomas.\n",
        "        SOLUTIONS (numpy.ndarray): Espacio de soluciones.\n",
        "    \"\"\"\n",
        "    def __init__(self, chromosomes):\n",
        "        self.chromosomes = chromosomes\n",
        "\n",
        "    def get_indiviudals(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class TournamentSelection(Selection):\n",
        "    \"\"\"\n",
        "    Clase para representar la selección por torneo en un algoritmo genético.\n",
        "\n",
        "    Args:\n",
        "        chromosomes (list): Lista de cromosomas.\n",
        "        SOLUTIONS (numpy.ndarray): Espacio de soluciones.\n",
        "        k (int): Tamaño del torneo.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chromosomes, k=3):\n",
        "        self.chromosomes = chromosomes\n",
        "        self.k = k\n",
        "\n",
        "    def tournament(self, selected_individuals):\n",
        "        participants = [chromosome for chromosome in self.chromosomes if chromosome not in selected_individuals]\n",
        "        participants = random.sample(participants, self.k)\n",
        "        participants.sort(key=lambda x: x.fitness)\n",
        "        winner = participants[0]\n",
        "        return winner\n",
        "\n",
        "    def get_indiviudals(self, n_repetition=10):\n",
        "        selected = []\n",
        "        for _ in range(n_repetition):\n",
        "            winner = self.tournament(selected)\n",
        "            selected.append(winner)\n",
        "        return selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QWUNRMXT-HtT"
      },
      "outputs": [],
      "source": [
        "NUM_POP = 50#[40, 50, 60, 70, 80, 90, 100]\n",
        "k_sample = 20#[10, 20, 30, 40]\n",
        "EPOCHS = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gVyx9kEsCZ1A"
      },
      "outputs": [],
      "source": [
        "def genetic_algorithm(train_loader, val_loader, test_loader, model, criterion,\\\n",
        "                      epochs=5, learning_rate=1e-4, image_size = (64, 64), neurons_candidates = [32, 64, 128, 256, 512],\\\n",
        "                      NUM_POP=50, generations=10, k_sample=20, percentage_parents_selection=0.7, crossover_rate=0.5, \\\n",
        "                      percentage_elitism=0.1, mutation_rate=0.5\n",
        "                      ):\n",
        "  #init population\n",
        "  pop = init_pop(NUM_POP, neurons_candidates = neurons_candidates)\n",
        "  chromosome = build_chromosome(pop, train_loader, val_loader, test_loader, model, criterion,\\\n",
        "                     epochs=epochs, learning_rate=learning_rate, image_size=image_size)\n",
        "\n",
        "  tournament_selecciton = TournamentSelection(chromosome, k=k_sample)\n",
        "  history_best_fitness = []\n",
        "\n",
        "  for g in generations:\n",
        "      print(f\"===Generation: {g}/{generations}===\")\n",
        "      random.shuffle(chromosome)\n",
        "      new_population = []\n",
        "      num_parents_candidates = int(len(chromosome)*percentage_parents_selection)\n",
        "      #parents selection step\n",
        "      selected_parents = tournament_selecciton.get_indiviudals(num_parents_candidates)\n",
        "\n",
        "      random.shuffle(selected_parents)\n",
        "      #crossover step\n",
        "      for i in range(0, len(selected_parents), 2):\n",
        "        if i + 1 < len(selected_parents):\n",
        "            parent1 = selected_parents[i]\n",
        "            parent2 = selected_parents[i + 1]\n",
        "\n",
        "            descendant1, descendant2 = crossover_two_points(parent1.chromosome, parent2.chromosome, crossover_rate=crossover_rate)\n",
        "            new_population.extend([descendant1, descendant2])\n",
        "\n",
        "      #mutation step\n",
        "      for i in range(len(new_population)):\n",
        "        new_population[i] = mutation(new_population[i], mutation_rate)\n",
        "      new_population = list(np.unique(new_population), axis=0)\n",
        "      new_chromosomes = build_chromosome(new_population, train_loader, val_loader, test_loader, model, criterion,\\\n",
        "                     epochs=epochs, learning_rate=learning_rate, image_size=image_size)\n",
        "\n",
        "      #best_fitness\n",
        "      new_chromosomes.sort(key=lambda x: x.fitness)\n",
        "      best_fitness= new_chromosomes[0]\n",
        "      history_best_fitness.append(best_fitness)\n",
        "\n",
        "      #generational gap\n",
        "      #elitism\n",
        "      new_chromosomes = new_chromosomes[:int(len(new_chromosomes) * percentage_elitism)]\n",
        "      chromosome[:len(new_chromosomes)] = new_chromosomes\n",
        "      print(f\"End generation, best fitness: {best_fitness.fitness} using config: {best_fitness.chromosome}\")\n",
        "  return history_best_fitness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jjbaGEvCTh7P"
      },
      "outputs": [],
      "source": [
        "genetic_algorithm(train_loader, val_loader, test_loader, EvolvedCNN, criterion,\\\n",
        "                      epochs=5, learning_rate=1e-4, image_size = (32, 32), neurons_candidates = [32, 64, 128, 256, 512],\\\n",
        "                      NUM_POP=15, generations=10, k_sample=5, percentage_parents_selection=0.8, crossover_rate=0.5, \\\n",
        "                      percentage_elitism=0.1, mutation_rate=0.5\n",
        "                      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfTakEgTfuby"
      },
      "source": [
        "#Tuning Parameters\n",
        "\n",
        "-  In this phase, we will optimize the hyperparameters of the Genetic Algorithm. We build instances for our Genetic Algorithm and optimize the numeric hyperparameters (such as num_pop, k_sample for tournament, crossover_rate, mutation_rate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_nJfrUsciL5Q"
      },
      "outputs": [],
      "source": [
        "num_vectors_params = 20\n",
        "\n",
        "def generate_parameter_vector(percentage_elitism_space, percentage_parents_selection_space,\n",
        "                              k_sample_space, num_pop_space, crossover_rate_space, mutation_rate):\n",
        "    \"\"\"\n",
        "    Generates a parameter vector for a genetic algorithm.\n",
        "\n",
        "    Args:\n",
        "        percentage_elitism_space (numpy.ndarray): Solution space for percentage_elitism.\n",
        "        percentage_parents_selection_space (numpy.ndarray): Solution space for percentage_parents_selection.\n",
        "        k_sample_space (numpy.ndarray): Solution space for k_sample.\n",
        "        num_pop_space (numpy.ndarray): Solution space for num_pop.\n",
        "        crossover_rate_space (numpy.ndarray): Solution space for crossover_rate.\n",
        "\n",
        "    Returns:\n",
        "        list: Parameter vector [percentage_elitism, percentage_parents_selection, k_sample, num_pop, crossover_rate].\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        random_percentage_elitism = np.random.choice(percentage_elitism_space)\n",
        "        random_percentage_parents_selection = np.random.choice(percentage_parents_selection_space)\n",
        "        random_k_sample = np.random.choice(k_sample_space)\n",
        "        random_num_pop = np.random.choice(num_pop_space)\n",
        "        random_crossover_rate = np.random.choice(crossover_rate_space)\n",
        "        random_mutation_rate = np.random.choice(mutation_rate)\n",
        "        if random_k_sample < random_num_pop:\n",
        "            break\n",
        "\n",
        "    return [random_percentage_elitism, random_percentage_parents_selection, random_k_sample, random_num_pop, random_crossover_rate, mutation_rate]\n",
        "\n",
        "def repet_genetic_algorithm(train_loader, val_loader, test_loader, EvolvedCNN, criterion,\\\n",
        "                      epochs=5, learning_rate=1e-4, image_size = (64, 64), neurons_candidates = [32, 64, 128, 256, 512],\\\n",
        "                      NUM_POP=15, generations=10, k_sample=5, percentage_parents_selection=0.7, crossover_rate=0.5, \\\n",
        "                      percentage_elitism=0.1, mutation_rate=0.5, num_repetition=10):\n",
        "\n",
        "    i = 0\n",
        "    repet_history_best_fitness = []\n",
        "    while i < num_repetition:\n",
        "        history_best_fitness = genetic_algorithm(train_loader, val_loader, test_loader, EvolvedCNN, criterion,\\\n",
        "                            epochs=epochs, learning_rate=learning_rate, image_size = image_size,\n",
        "                            neurons_candidates = neurons_candidates,\\\n",
        "                            NUM_POP=NUM_POP, generations=generations, k_sample=k_sample,\\\n",
        "                            percentage_parents_selection=percentage_parents_selection,\\\n",
        "                            crossover_rate=crossover_rate, percentage_elitism=percentage_elitism,\n",
        "                            mutation_rate=mutation_rate\n",
        "                            )\n",
        "        repet_history_best_fitness.append(history_best_fitness)\n",
        "        i+=1\n",
        "    return repet_history_best_fitness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-Hfdp3nmTUV",
        "outputId": "0a7eba22-198a-40ef-9493-859166acc591"
      },
      "outputs": [],
      "source": [
        "percentage_elitism_space = np.linspace(0.05, 0.2, 10)\n",
        "percentage_parents_selection_space = np.linspace(0.5, 0.9, 10)\n",
        "crossover_rate_space = np.linspace(0.5, 0.9, 10)\n",
        "mutation_rate = np.linspace(0.1, 0.9, 10)\n",
        "k_sample_space = np.arange(10, 40, 5)\n",
        "num_pop_space = np.arange(30, 80, 10)\n",
        "\n",
        "vectors_used = []\n",
        "N = 10\n",
        "while len(vectors_used) < N:\n",
        "  vector_parametros = generate_parameter_vector(percentage_elitism_space,\n",
        "                              percentage_parents_selection_space, k_sample_space, num_pop_space, crossover_rate_space, mutation_rate)\n",
        "\n",
        "  print(\"Vector de parámetros:\", vector_parametros)\n",
        "  repet_history_best = repet_genetic_algorithm(train_loader, val_loader, test_loader, EvolvedCNN, criterion,\\\n",
        "                      epochs=5, learning_rate=1e-4, image_size = (64, 64), neurons_candidates = [32, 64, 128, 256, 512],\\\n",
        "                      NUM_POP=vector_parametros[3], generations=10, k_sample=vector_parametros[2],\n",
        "                      percentage_parents_selection=vector_parametros[1], crossover_rate=vector_parametros[4], \\\n",
        "                      percentage_elitism=vector_parametros[0], mutation_rate=vector_parametros[5], num_repetition=10)\n",
        "  vectors_used.append((vector_parametros, repet_history_best))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
